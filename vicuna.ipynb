{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfc1732-d854-4323-b5c3-adb092b744e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -q bitsandbytes\n",
    "# !pip3 install -q datasets sentencepiece\n",
    "# !pip3 install -q git+https://github.com/huggingface/transformers\n",
    "# !pip3 install -q accelerate\n",
    "# !pip3 install -q safetensors\n",
    "# git clone https://github.com/oobabooga/GPTQ-for-LLaMa\n",
    "# cd GPTQ-for-LLaMa && python3 setup_cuda.py build && ln -s build/lib.*/*.so ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c551d7-2483-45fe-b737-80c9049ae256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THE OOBABOOGA VERSION OF GPTQ-FOR-LLAMA !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9230da52-ef94-4516-b504-cd7985002f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "from pathlib import Path\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import accelerate\n",
    "import ipywidgets as widgets\n",
    "sys.path.insert(0, \"./GPTQ-for-LLaMa\")\n",
    "\n",
    "import llama_inference_offload\n",
    "from modelutils import find_layers\n",
    "from quant import make_quant\n",
    "\n",
    "\n",
    "def _load_quant(model, checkpoint, wbits, groupsize=-1, faster_kernel=False, exclude_layers=['lm_head'], kernel_switch_threshold=128):\n",
    "    config = AutoConfig.from_pretrained(model)\n",
    "    def noop(*args, **kwargs):\n",
    "        pass\n",
    "    torch.nn.init.kaiming_uniform_ = noop \n",
    "    torch.nn.init.uniform_ = noop \n",
    "    torch.nn.init.normal_ = noop \n",
    "\n",
    "    torch.set_default_dtype(torch.half)\n",
    "    transformers.modeling_utils._init_weights = False\n",
    "    torch.set_default_dtype(torch.half)\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "    torch.set_default_dtype(torch.float)\n",
    "    model = model.eval()\n",
    "    layers = find_layers(model)\n",
    "    for name in exclude_layers:\n",
    "        if name in layers:\n",
    "            del layers[name]\n",
    "    make_quant(model, layers, wbits, groupsize)\n",
    "    del layers\n",
    "    \n",
    "    print('Loading model ...')\n",
    "    from safetensors.torch import load_file as safe_load\n",
    "    model.load_state_dict(safe_load(checkpoint))\n",
    "    model.seqlen = 1024\n",
    "    print('Done.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625ebd87-9b03-4735-ba00-23377df1ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'vicuna-13b-GPTQ-4bit-128g'\n",
    "pt_path = 'vicuna-13b-GPTQ-4bit-128g/vicuna-13b-4bit-128g.safetensors'\n",
    "\n",
    "model = _load_quant(model_path, pt_path, 4, 128)\n",
    "model = model.to(torch.device('cuda:0'))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ddefe1-5700-477a-9c18-6d95367e40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_memory = {0: \"9GiB\", \"cpu\": \"30GiB\"}\n",
    "device_map = accelerate.infer_auto_device_map(model, max_memory=max_memory, no_split_module_classes=[\"LlamaDecoderLayer\"])\n",
    "model = accelerate.dispatch_model(model, device_map=device_map, offload_buffers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ccba39-9f23-4873-93ba-487760f23b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_generation_conf = GenerationConfig(\n",
    "    top_k=40,\n",
    "    temperature=0.1,\n",
    "    top_p=0.75,\n",
    "    max_new_tokens=20\n",
    ")\n",
    "\n",
    "def inference (prompt, conf = default_generation_conf):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    r = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"].cuda(),\n",
    "        generation_config=conf\n",
    "    )\n",
    "    return [tokenizer.decode(x) for x in r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b026bbe-31d1-4c11-974a-79d3b794fbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6fd5e17c014d99931faed2d1f4712e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Once upon a time', description='Prompt:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39aefec70f1342f7b2e38f2f5e3464c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click me', icon='check', style=ButtonStyle(), tooltip='Click me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f7c91db33040ef81366da3a70dd7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = widgets.Text(\n",
    "    value='Once upon a time',\n",
    "    placeholder='Type something',\n",
    "    description='Prompt:',\n",
    "    disabled=False   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "output = widgets.Output()\n",
    "display(text, button, output)\n",
    "\n",
    "conf = GenerationConfig(\n",
    "    top_k=40,\n",
    "    temperature=0.1,\n",
    "    top_p=0.75,\n",
    "    max_new_tokens=20,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "def on_button_clicked (b):\n",
    "    out = inference(text.value, conf)\n",
    "    with output:\n",
    "        print('--------')\n",
    "        for l in out:\n",
    "            print(l)\n",
    "            \n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54140aae-327d-455c-9621-b204668a7968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b131b81631745c898a63c446c6473cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Once upon a time', description='Prompt:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d55ad13b2546ca99b5995530da0aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('bad_words_ids', 'begin_suppress_tokens', 'bos_token_id', 'constraints', 'decoder_start_tokeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59d3ba5a8154c10ac9c055598c21264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae35de716e34a34adf02a2083ce176c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click me', icon='check', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0d06eb0f17422f938006b094e476dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = []\n",
    "for key in dir(default_conf):\n",
    "    if '__' in key:\n",
    "        continue\n",
    "    if key[0] == '_':\n",
    "        continue\n",
    "    params.append(key)\n",
    "\n",
    "text = widgets.Text(value='Once upon a time',description='Prompt:',disabled=False)\n",
    "dropdown = widgets.Dropdown(options=params,value=params[0],disabled=False)\n",
    "options = widgets.Text(value='',placeholder='',description='',disabled=False)\n",
    "button = widgets.Button(description='Click me',disabled=False,icon='check')\n",
    "output = widgets.Output()\n",
    "display(text, dropdown, options, button, output)\n",
    "\n",
    "def on_button_clicked2 (b):\n",
    "    param = dropdown.value\n",
    "    values = []\n",
    "    for v in options.value.split(';'):\n",
    "        v = v.strip()\n",
    "        values.append(float(v))\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        for v in values:\n",
    "            args = dict(top_k=40,temperature=0.1,top_p=0.75,max_new_tokens=10,num_return_sequences=1)\n",
    "            args[param] = v\n",
    "            conf = GenerationConfig(**args)\n",
    "            out = inference(text.value, conf)\n",
    "            print('----%s = %g ----' % (param, getattr(conf, param)))\n",
    "            for l in out:\n",
    "                print(l)\n",
    "                \n",
    "def on_change (change):\n",
    "    param = dropdown.value\n",
    "    v = getattr(default_conf, param)\n",
    "    options.value = str(v)\n",
    "            \n",
    "button.on_click(on_button_clicked2)\n",
    "dropdown.observe(on_change)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
